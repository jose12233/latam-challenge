{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto: Análisis de Tweets\n",
    "\n",
    "## Descripción del Proyecto\n",
    "En este proyecto, realizaremos un análisis de datos a partir de un conjunto de tweets almacenados en un archivo JSON. Las tareas incluirán la optimización del procesamiento de datos y la generación de informes sobre la actividad de los usuarios en Twitter.\n",
    "\n",
    "## Workflow\n",
    "Utilizaremos **Gitflow** como nuestro flujo de trabajo para la gestión de versiones y el desarrollo del proyecto. Las principales ramas que se han creado son:\n",
    "\n",
    "- **main**: Esta es la rama principal que contiene la versión estable del proyecto.\n",
    "- **develop**: Esta rama es la base para el desarrollo de nuevas características. Todos los cambios se integrarán aquí antes de ser enviados a la rama principal.\n",
    "  \n",
    "Para cada nueva característica o función, se creará una rama de desarrollo específica (`feature/<nombre-de-la-funcion>`). Esto permitirá un desarrollo organizado y la posibilidad de trabajar en múltiples funciones simultáneamente sin interferencias.\n",
    "\n",
    "## Estructura del Proyecto\n",
    "- **main**: Contiene la versión estable del proyecto.\n",
    "- **develop**: Rama para integrar nuevas características.\n",
    "- **feature/**: Ramas individuales para el desarrollo de funciones específicas.\n",
    "\n",
    "## Tecnologías Utilizadas\n",
    "- Python: Lenguaje de programación principal.\n",
    "- Pandas: Librería para la manipulación y análisis de datos.\n",
    "- Git: Sistema de control de versiones.\n",
    "- Gitflow: Modelo de ramificación para gestionar el flujo de trabajo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimización de Tiempo: Función `count_dates_and_users`  (q1_time)\n",
    "\n",
    "## Descripción\n",
    "La función `count_dates_and_users` se encarga de procesar un archivo JSON que contiene registros de tweets y extraer información sobre la actividad de los usuarios en función de las fechas. El objetivo principal de esta función es optimizar el tiempo de ejecución al utilizar estructuras de datos eficientes y un enfoque de procesamiento línea por línea.\n",
    "\n",
    "## Detalles de Implementación\n",
    "\n",
    "### Importaciones\n",
    "La función utiliza las siguientes librerías:\n",
    "- `os`: Para manejar rutas de archivos.\n",
    "- `json`: Para cargar los registros de tweets en formato JSON.\n",
    "- `time`: Para medir el tiempo de ejecución.\n",
    "- `Counter` de `collections`: Para contar la cantidad de tweets por usuario en cada fecha.\n",
    "- `datetime`: Para manejar las fechas de manera adecuada.\n",
    "\n",
    "### Proceso\n",
    "1. **Inicialización**: Se inicializa un diccionario `date_user_counter` para contar la cantidad de tweets por usuario en cada fecha.\n",
    "  \n",
    "2. **Lectura del Archivo**: Se lee el archivo línea por línea. Cada línea se procesa como un objeto JSON:\n",
    "   - Se extraen la fecha y el nombre de usuario.\n",
    "   - La fecha se simplifica a solo la parte de la fecha (sin la hora).\n",
    "   - Se utiliza `Counter` para llevar un registro de la cantidad de tweets por usuario en cada fecha.\n",
    "\n",
    "3. **Manejo de Errores**: Se implementa un manejo de errores para ignorar líneas que no se puedan decodificar como JSON.\n",
    "\n",
    "4. **Cálculo de Resultados**:\n",
    "   - Se obtienen las 10 fechas más comunes y la suma de tweets por usuario en cada fecha.\n",
    "   - Para cada una de estas fechas, se determina el usuario más activo.\n",
    "\n",
    "5. **Tiempo de Ejecución**: Se mide el tiempo total que toma ejecutar la función.\n",
    "\n",
    "### Salida\n",
    "La función retorna dos valores:\n",
    "- Una lista de tuplas que contiene las 10 fechas más comunes junto con el usuario más activo en esas fechas.\n",
    "- El tiempo de ejecución de la función.\n",
    "\n",
    "### Ejecución\n",
    "Finalmente, se llama a la función pasando la ruta del archivo JSON como argumento y se imprimen los resultados.\n",
    "\n",
    "## Conclusión\n",
    "Esta implementación permite optimizar el procesamiento de grandes volúmenes de datos de tweets, reduciendo significativamente el tiempo de ejecución en comparación con enfoques más ineficientes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salida estándar:\n",
      "Top 10 fechas mas comunes con el usuario mas activo:\n",
      "[(datetime.date(2021, 2, 12), 'RanbirS00614606'), (datetime.date(2021, 2, 13), 'MaanDee08215437'), (datetime.date(2021, 2, 17), 'RaaJVinderkaur'), (datetime.date(2021, 2, 16), 'jot__b'), (datetime.date(2021, 2, 14), 'rebelpacifist'), (datetime.date(2021, 2, 18), 'neetuanjle_nitu'), (datetime.date(2021, 2, 15), 'jot__b'), (datetime.date(2021, 2, 20), 'MangalJ23056160'), (datetime.date(2021, 2, 23), 'Surrypuria'), (datetime.date(2021, 2, 19), 'Preetm91')]\n",
      "Tiempo de ejecucion : 3.7000 segundos\n",
      "\n",
      "Errores:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import subprocess\n",
    "# Ruta del script que deseas ejecutar\n",
    "script_path = './q1_time.py'\n",
    "\n",
    "# Ejecuta el script\n",
    "result = subprocess.run(['python', script_path], capture_output=True, text=True)\n",
    "\n",
    "# Imprime la salida del script\n",
    "print('Salida estándar:')\n",
    "print(result.stdout)\n",
    "\n",
    "# Imprime errores si los hay\n",
    "print('Errores:')\n",
    "print(result.stderr)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimización de Memoria en la Función `count_dates_and_users`\n",
    "\n",
    "## Descripción de la Función\n",
    "\n",
    "La función `count_dates_and_users` se encarga de analizar un archivo JSON que contiene tweets, extrayendo la fecha y el nombre de usuario para contar cuántas veces cada usuario tuitea en cada fecha. El objetivo es encontrar las 10 fechas más comunes y el usuario más activo en cada una de esas fechas.\n",
    "\n",
    "## Cambios Realizados\n",
    "\n",
    "1. **Uso de `defaultdict`**:\n",
    "   - Se utilizó `defaultdict` en lugar de un diccionario estándar para el contador de fechas y usuarios. Esto elimina la necesidad de inicializar un contador para cada fecha manualmente, lo que reduce el uso de memoria y mejora la eficiencia del código.\n",
    "\n",
    "2. **Bloque `if __name__ == '__main__':`**:\n",
    "   - Se agregó este bloque para proteger el código principal que se ejecuta al iniciar el script. Esto es especialmente importante en sistemas operativos Windows, donde el módulo `multiprocessing` requiere esta estructura para evitar errores de importación.\n",
    "\n",
    "3. **Monitoreo del Uso de Memoria**:\n",
    "   - Se implementó el uso de la biblioteca `memory_profiler` para rastrear el uso de memoria durante la ejecución de la función. Esto permite identificar picos de uso de memoria y optimizar el código según sea necesario.\n",
    "\n",
    "## Ventajas de la Optimización\n",
    "\n",
    "- **Eficiencia en el Uso de Memoria**:\n",
    "  - La implementación de `defaultdict` minimiza el espacio en memoria requerido para almacenar contadores al evitar inicializaciones innecesarias. Esto es especialmente útil cuando se procesan grandes volúmenes de datos.\n",
    "\n",
    "- **Robustez del Código**:\n",
    "  - Al incluir el bloque `if __name__ == '__main__':`, el código se vuelve más seguro y compatible con diferentes entornos de ejecución, evitando problemas al crear nuevos procesos.\n",
    "\n",
    "- **Capacidad de Monitoreo**:\n",
    "  - El uso de `memory_profiler` permite un análisis detallado del consumo de memoria, facilitando la identificación de áreas que podrían necesitar optimización en futuras implementaciones.\n",
    "\n",
    "Estos cambios no solo hacen que la función sea más eficiente en términos de uso de memoria, sino que también mejoran su robustez y capacidad de monitoreo, lo cual es esencial al trabajar con grandes conjuntos de datos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 fechas más comunes con el usuario más activo:\n",
      "[(datetime.date(2021, 2, 12), 'RanbirS00614606'), (datetime.date(2021, 2, 13), 'MaanDee08215437'), (datetime.date(2021, 2, 17), 'RaaJVinderkaur'), (datetime.date(2021, 2, 16), 'jot__b'), (datetime.date(2021, 2, 14), 'rebelpacifist'), (datetime.date(2021, 2, 18), 'neetuanjle_nitu'), (datetime.date(2021, 2, 15), 'jot__b'), (datetime.date(2021, 2, 20), 'MangalJ23056160'), (datetime.date(2021, 2, 23), 'Surrypuria'), (datetime.date(2021, 2, 19), 'Preetm91')]\n",
      "Tiempo de ejecución: 2.8413 segundos\n",
      "Uso de memoria (en MiB): 3.09375\n"
     ]
    }
   ],
   "source": [
    "# Importar los módulos necesarios\n",
    "import os\n",
    "import sys\n",
    "from memory_profiler import memory_usage\n",
    "\n",
    "# Asegúrate de que la ruta al archivo q1_memory.py está en el sistema\n",
    "sys.path.append(os.path.join(os.getcwd(), 'src'))\n",
    "\n",
    "# Importar la función del archivo\n",
    "from q1_memory import count_dates_and_users\n",
    "\n",
    "# Definir la ruta al archivo JSON\n",
    "file_path = os.path.join(os.getcwd(), '..', 'farmers-protest-tweets-2021-2-4.json')\n",
    "\n",
    "# Función envoltorio para medir el uso de memoria\n",
    "def wrapper_function():\n",
    "    return count_dates_and_users(file_path)\n",
    "\n",
    "# Medir el uso de memoria\n",
    "mem_usage = memory_usage(wrapper_function)\n",
    "\n",
    "# Llamar a la función\n",
    "top_dates_with_users, execution_time = wrapper_function()\n",
    "\n",
    "# Mostrar los resultados\n",
    "print(\"Top 10 fechas más comunes con el usuario más activo:\")\n",
    "print(top_dates_with_users)\n",
    "print(f\"Tiempo de ejecución: {execution_time:.4f} segundos\")\n",
    "\n",
    "# Mostrar el uso de memoria\n",
    "print(f\"Uso de memoria (en MiB): {max(mem_usage) - min(mem_usage)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimización de Tiempo en la Función count_emojis_in_content\n",
    "# Descripción de la Función\n",
    "La función count_emojis_in_content procesa un archivo JSON de tweets, extrayendo el contenido de cada tweet en la clave content y utilizando expresiones regulares para identificar y contar los emojis en cada uno. El objetivo es encontrar los 10 emojis más comunes en todo el dataset.\n",
    "\n",
    "# Cambios Realizados\n",
    "Filtro más preciso de emojis:\n",
    "Se utilizó una expresión regular mejorada para identificar solo los caracteres que pertenecen al rango Unicode de emojis, ignorando otros caracteres no deseados como letras o símbolos especiales que se estaban contando incorrectamente.\n",
    "\n",
    "Optimización del procesamiento de archivos:\n",
    "En lugar de cargar todo el archivo JSON en memoria, el procesamiento se realiza línea por línea, lo cual es más eficiente en términos de tiempo y memoria. Esto evita consumir grandes cantidades de memoria al procesar archivos grandes.\n",
    "\n",
    "Uso de Counter para el conteo de emojis:\n",
    "Se implementó collections.Counter para contar las ocurrencias de los emojis de manera eficiente. Counter es una estructura de datos optimizada para este tipo de tareas, reduciendo el tiempo de ejecución en comparación con métodos manuales.\n",
    "\n",
    "# Ventajas de la Optimización\n",
    "Eficiencia en el Tiempo de Ejecución:\n",
    "La mejora en el filtrado de emojis con expresiones regulares más precisas y el uso de Counter permitió reducir el tiempo de ejecución de la función. Esto es clave al procesar grandes volúmenes de datos en un archivo JSON con más de 120,000 registros.\n",
    "\n",
    "Precisión en la Captura de Emojis:\n",
    "La expresión regular fue ajustada para eliminar falsos positivos, como letras y otros caracteres que inicialmente aparecían en el top de emojis. Ahora, los resultados reflejan únicamente emojis válidos, evitando confusiones como 'IN' o partes de banderas que se contaban por separado.\n",
    "\n",
    "Escalabilidad y Manejo de Grandes Volúmenes de Datos:\n",
    "El procesamiento línea por línea y el uso eficiente de estructuras de datos permiten que el algoritmo sea escalable, manejando archivos grandes sin impactar negativamente en el rendimiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salida estándar:\n",
      "Top 10 emojis más comunes:\n",
      "[('🙏', 7286), ('😂', 3072), ('🚜', 2972), ('✊', 2411), ('🌾', 2363), ('🇮', 2096), ('🇳', 2094), ('🏻', 2080), ('❤', 1779), ('🏽', 1218)]\n",
      "Tiempo de ejecución: 4.8666 segundos\n",
      "\n",
      "Errores:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "# Ruta del script que deseas ejecutar\n",
    "script_path = './q2_time.py'\n",
    "\n",
    "# Ejecuta el script con la codificación utf-8\n",
    "result = subprocess.run(['python', script_path], capture_output=True, text=True, encoding='utf-8')\n",
    "\n",
    "# Imprime la salida estándar del script\n",
    "print(\"Salida estándar:\")\n",
    "print(result.stdout)\n",
    "\n",
    "# Imprime errores si los hay\n",
    "print(\"Errores:\")\n",
    "print(result.stderr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimización de Memoria en la Función count_emojis_in_content\n",
    "Descripción de la Función\n",
    "La función count_emojis_in_content tiene como objetivo analizar un archivo JSON de tweets, extrayendo emojis presentes en el contenido de cada tweet y contando su frecuencia. Además, el código incluye una medición del uso de memoria durante su ejecución.\n",
    "\n",
    "# Cambios Realizados\n",
    "Optimización de la Expresión Regular para Emojis:\n",
    "Se utilizó una expresión regular optimizada para capturar una amplia variedad de emojis y otros símbolos relevantes. Se mejoró su desempeño al limitar los rangos a aquellos necesarios para encontrar emojis y símbolos de interés.\n",
    "\n",
    "Uso de Counter para Conteo Eficiente:\n",
    "Se utilizó la estructura Counter de la biblioteca collections, lo que permite realizar el conteo de emojis de manera más eficiente y con menor impacto en el uso de memoria.\n",
    "\n",
    "Encapsulación del Código Principal en un Bloque if __name__ == '__main__'::\n",
    "Este cambio garantiza que la función principal solo se ejecute cuando el script se ejecute directamente, evitando errores relacionados con la creación de procesos múltiples en sistemas operativos como Windows. Esto es importante ya que memory_profiler \n",
    "utiliza múltiples procesos para realizar el análisis de memoria.\n",
    "\n",
    "Implementación de memory_profiler para Medir el Uso de Memoria:\n",
    "Se utilizó la función memory_usage de la biblioteca memory_profiler para rastrear el uso de memoria durante la ejecución de la función count_emojis_in_content. Este monitoreo en tiempo real ayuda a identificar picos y cuellos de botella en el uso de recursos.\n",
    "\n",
    "Evitación de la Carga Completa en Memoria:\n",
    "En lugar de cargar todo el archivo JSON de tweets en memoria, se procesó el archivo línea por línea. Esto permite que el código maneje grandes archivos sin agotar la memoria, ya que solo mantiene en memoria la línea actual que está siendo procesada.\n",
    "\n",
    "# Ventajas de la Optimización\n",
    "Eficiencia en el Uso de Memoria:\n",
    "Procesar el archivo JSON línea por línea minimiza el uso de memoria, lo que es crucial cuando se trabaja con grandes volúmenes de datos.\n",
    "\n",
    "Medición Detallada del Consumo de Memoria:\n",
    "Al implementar memory_profiler, se obtiene una visión clara del uso máximo de memoria durante la ejecución. Esto permite optimizar y ajustar el código según las necesidades de escalabilidad.\n",
    "\n",
    "Reducción del Sobrecargo en la CPU:\n",
    "La combinación de Counter y un procesamiento incremental del archivo reduce la carga computacional al evitar operaciones costosas en memoria y cálculos repetidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 emojis más comunes:\n",
      "[('🙏', 7286), ('😂', 3072), ('🚜', 2972), ('✊', 2411), ('🌾', 2363), ('🇮', 2096), ('🇳', 2094), ('🏻', 2080), ('❤', 1779), ('🏽', 1218)]\n",
      "Tiempo de ejecución: 2.7618 segundos\n",
      "Uso de memoria (en MiB): 0.3359375\n"
     ]
    }
   ],
   "source": [
    "# Importar los módulos necesarios\n",
    "import os\n",
    "import sys\n",
    "from memory_profiler import memory_usage\n",
    "\n",
    "# Asegúrate de que la ruta al archivo q2_memory.py está en el sistema\n",
    "sys.path.append(os.path.join(os.getcwd(), 'src'))\n",
    "\n",
    "# Importar la función del archivo\n",
    "from q2_memory import count_emojis_in_content\n",
    "\n",
    "# Definir la ruta al archivo JSON\n",
    "file_path = os.path.join(os.getcwd(), '..', 'farmers-protest-tweets-2021-2-4.json')\n",
    "\n",
    "# Función envoltorio para medir el uso de memoria\n",
    "def wrapper_function():\n",
    "    return count_emojis_in_content(file_path)\n",
    "\n",
    "# Medir el uso de memoria\n",
    "mem_usage = memory_usage(wrapper_function)\n",
    "\n",
    "# Llamar a la función\n",
    "top_emojis, execution_time = wrapper_function()\n",
    "\n",
    "# Mostrar los resultados\n",
    "print(\"Top 10 emojis más comunes:\")\n",
    "print(top_emojis)\n",
    "print(f\"Tiempo de ejecución: {execution_time:.4f} segundos\")\n",
    "\n",
    "# Mostrar el uso de memoria\n",
    "print(f\"Uso de memoria (en MiB): {max(mem_usage) - min(mem_usage)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Función para Contar Menciones en Tweets\n",
    "Esta función se encarga de identificar y contar las menciones a usuarios en los tweets del archivo JSON, excluyendo el símbolo '@' de los nombres de usuario. Devuelve las diez menciones más frecuentes junto con su conteo.\n",
    "\n",
    "# Implementación y Optimización\n",
    "Expresiones Regulares: Utiliza una expresión regular eficiente (@(\\w+)) para capturar nombres de usuario directamente, lo que acelera el proceso de identificación de menciones.\n",
    "\n",
    "Lectura Eficiente: Procesa el archivo línea por línea, lo que ahorra memoria y mejora la velocidad de ejecución al permitir que los tweets se analicen en tiempo real.\n",
    "\n",
    "Contador Eficiente: Emplea collections.Counter para realizar un conteo rápido y optimizado de las menciones.\n",
    "\n",
    "# Resultado\n",
    "La función retorna una lista de las diez menciones más comunes en el formato [(username, count), ...] y el tiempo total de ejecución."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 usuarios más mencionados:\n",
      "([('narendramodi', 2261), ('Kisanektamorcha', 1836), ('RakeshTikaitBKU', 1639), ('PMOIndia', 1422), ('RahulGandhi', 1125), ('GretaThunberg', 1046), ('RaviSinghKA', 1015), ('rihanna', 972), ('UNHumanRights', 962), ('meenaharris', 925)], 2.684865713119507)\n",
      "Tiempo de ejecución: 2.6849 segundos\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "# Ruta del archivo q3_time.py\n",
    "script_path = os.path.join(os.getcwd(), 'q3_time.py')\n",
    "\n",
    "# Importar la función desde el archivo\n",
    "from q3_time import count_mentions_in_content\n",
    "\n",
    "# Definir la ruta al archivo JSON\n",
    "file_path = os.path.join(os.getcwd(), '..', 'farmers-protest-tweets-2021-2-4.json')\n",
    "\n",
    "# Medir el tiempo de ejecución\n",
    "start_time = time.time()\n",
    "top_mentions = count_mentions_in_content(file_path)\n",
    "elapsed_time = time.time() - start_time\n",
    "\n",
    "# Mostrar resultados\n",
    "print(\"Top 10 usuarios más mencionados:\")\n",
    "print(top_mentions)\n",
    "print(f\"Tiempo de ejecución: {elapsed_time:.4f} segundos\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reflexiones Finales\n",
    "Este reto ha sido una experiencia sumamente interesante y enriquecedora. La optimización del código es crucial cuando se trabaja con grandes volúmenes de datos, como los tweets analizados en este proyecto. A medida que los conjuntos de datos crecen, las técnicas tradicionales de programación pueden llegar a su límite, especialmente en términos de complejidad, que se reduce a O(n) o O(1).\n",
    "\n",
    "Para llevar el procesamiento de datos más allá de estos límites, sería esencial aplicar técnicas de Big Data. Una estrategia efectiva podría ser el uso de clustering para organizar y analizar la información de manera más eficiente. Si el tamaño de los datos lo requiere, consideraría utilizar PySpark para el procesamiento distribuido, lo que permitiría manejar grandes volúmenes de información de forma más escalable. Además, aprovechar servicios en la nube, como los que ofrece AWS, podría facilitar la implementación de estas técnicas, garantizando un manejo más robusto y eficiente de los datos."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
